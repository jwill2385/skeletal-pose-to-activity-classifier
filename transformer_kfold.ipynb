{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script will be used to train and run a transformer model for classifying basketball activity<br>\n",
    "Users must manually input the data parquet files where each row is a separate basketball event that tracks player joints over a 21 frame window. Note this script takes in flattened data values.<br>\n",
    "For example lets say we were analyzing a combination with 10 joints, the pose_data column contains a single flattend row of the 21 frames * 10 joints * 3 (x,y,z) position of each joint. This data needs to be unflattened before processed to easily map each coordinate to the correct joint\n",
    "\n",
    "*The input dataframe has the following columns of interest*:\n",
    "\n",
    " ['game_id', 'stadium_id', 'player_id', 'team_id',\n",
    "'event_seq_id', 'event_type', 'ball_position', 'player_com', 'pose_data', 'label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries and Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import data files\n",
    "# add file path location of the parquet files storing the joint data per event type.\n",
    "\n",
    "dribble_file = ''\n",
    "pass_file = ''\n",
    "shot_file = ''\n",
    "rebound_file = ''\n",
    "\n",
    "# NOTE update this variable for how many joints we are looking at\n",
    "num_joints = 7\n",
    "# Load parquet file\n",
    "dribble_df = pd.read_parquet(dribble_file)\n",
    "passing_df = pd.read_parquet(pass_file)\n",
    "shooting_df = pd.read_parquet(shot_file)\n",
    "rebound_df = pd.read_parquet(rebound_file)\n",
    "\n",
    "# Combine data from all event types into one dataframe\n",
    "all_data = pd.concat([dribble_df, passing_df, shooting_df, rebound_df])\n",
    "\n",
    "# Define the expected pose vector length NOTE this changes if I'm using 5 joints vs 6 vs 7 etc\n",
    "# 21 frame pose window * number of joints * 3 (x, y, z coordinates)\n",
    "expected_pose_length = 21 * num_joints * 3\n",
    "\n",
    "# Filter out rows with inconsistent pose_data lengths (This removes incomplete pose windows)\n",
    "all_data = all_data[all_data['pose_data'].apply(lambda x: len(x) == expected_pose_length if isinstance(x, (list, np.ndarray)) else False)]\n",
    "\n",
    "# Map event_type to integer labels\n",
    "event_type_mapping = {'dribble': 0, 'pass': 1, 'shot': 2, 'rebound': 3}\n",
    "all_data['label'] = all_data['event_type'].map(event_type_mapping)\n",
    "\n",
    "shapes = all_data['pose_data'].apply(lambda x: len(x) if isinstance(x, (list, np.ndarray)) else None)\n",
    "\n",
    "com_shapes = all_data['player_com'].apply(lambda x: len(x) if isinstance(x, (list, np.ndarray)) else None)\n",
    "\n",
    "ball_shapes = all_data['ball_position'].apply(lambda x: len(x) if isinstance(x, (list, np.ndarray)) else None)\n",
    "\n",
    "# Combine pose_data, ball_position, and player_com\n",
    "pose_data = torch.tensor(all_data['pose_data'].tolist(), dtype=torch.float32)  # Shape: [num_samples, 21 x 51]\n",
    "ball_data = torch.tensor(all_data['ball_position'].tolist(), dtype=torch.float32)  # Shape: [num_samples, 21 x3]\n",
    "com_data = torch.tensor(all_data['player_com'].tolist(), dtype=torch.float32)  # Shape: [num_samples, 21 x 3]\n",
    "\n",
    "sequence_length = 21 # we have 21 frame windows\n",
    "num_features = 3 # x,y,z\n",
    "\n",
    "# We have to unflatten data here before concatenating to put into correct shape\n",
    "pose_data = pose_data.view(-1, sequence_length, num_joints * num_features)\n",
    "com_data = com_data.view(-1, sequence_length, num_features)\n",
    "\n",
    "#combine pose and com data\n",
    "combined_data = torch.cat((pose_data, com_data), dim=2)  # Shape: [num_samples, sequence_length, num_joints x features + 3]\n",
    "labels = torch.tensor(all_data['label'].values, dtype=torch.long)  # Shape: [num_samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "# Define the transformer model\n",
    "\"\"\"\n",
    "\n",
    "The PoseTransformer model is a transformer model that takes as input a sequence of pose data and outputs a classification prediction. The model consists of the following components:\n",
    "\n",
    "    An embedding layer to map the input pose data to the transformer embedding size.\n",
    "    A learnable positional encoding to provide positional information to the transformer.\n",
    "    A classification token to aggregate information from the transformer output.\n",
    "    A transformer encoder that processes the input sequence.\n",
    "    A classification head that takes the output of the classification token and predicts the class label.\n",
    "    \n",
    "\"\"\"\n",
    "class PoseTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, sequence_length, num_joints, num_features, d_model, nhead, num_layers, num_classes, dropout=0.1):\n",
    "        super(PoseTransformer, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, d_model)  # Map input to transformer embedding size\n",
    "        self.positional_encoding = nn.Parameter(torch.zeros(sequence_length, d_model))  # Learnable positional encoding\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, d_model))  # Learnable classification token.\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            num_encoder_layers=num_layers,\n",
    "            num_decoder_layers=1,\n",
    "            dropout=dropout,\n",
    "            batch_first=True  # Input shape: [Batch Size, Sequence Length, Features]\n",
    "        )\n",
    "        self.classifier = nn.Linear(d_model, num_classes)  # Classification head\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input shape: [Batch Size, Sequence Length, Input Dim]\n",
    "        batch_size, seq_len, input_dim = x.shape\n",
    "\n",
    "        # Embed the input features: [Batch Size, Sequence Length, d_model]\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # Add positional encoding\n",
    "        x = x + self.positional_encoding.unsqueeze(0).expand(batch_size, -1, -1)\n",
    "\n",
    "        # Prepare the classification token: [Batch Size, 1, d_model]\n",
    "        cls_token = self.cls_token.expand(batch_size, -1, -1)\n",
    "\n",
    "        # Transformer expects inputs in shape [Batch Size, Seq Len, d_model]\n",
    "        # Concatenate cls_token to the beginning of the source sequence\n",
    "        src = torch.cat([cls_token, x], dim=1)\n",
    "\n",
    "        # Simple target: Use the same cls_token for simplicity. We are just using 1 layer decoder\n",
    "        tgt = cls_token\n",
    "\n",
    "        # Pass through Transformer\n",
    "        transformer_output = self.transformer(src=src, tgt=tgt)\n",
    "\n",
    "        # Use the output of the classification token for classification\n",
    "        cls_output = transformer_output[:, 0, :]  # Output corresponding to the cls_token\n",
    "\n",
    "        # Classification head\n",
    "        output = self.classifier(cls_output)\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below cell balances dataset by augmenting smaller classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(data, noise_std=0.01):\n",
    "    \"\"\"\n",
    "    Add Gaussian noise to the input data.\n",
    "    \n",
    "    Args:\n",
    "    data (torch.Tensor): Input data\n",
    "    noise_std (float): Standard deviation of the Gaussian noise\n",
    "    \n",
    "    Returns:\n",
    "    torch.Tensor: Noisy data\n",
    "    \"\"\"\n",
    "    noise = noise_std * torch.randn_like(data)\n",
    "    return data + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Model Augmentation Functions and KFold Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "### Save and Load Data ###\n",
    "def save_checkpoint(model, optimizer, epoch, filename=\"best_model.pth\"):\n",
    "\n",
    "    \"\"\"Save the model checkpoint.\"\"\"\n",
    "    checkpoint = {\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'epoch': epoch\n",
    "    }\n",
    "    torch.save(checkpoint, filename)\n",
    "    print(f\"Model saved as {filename}\")\n",
    "\n",
    "def load_checkpoint(model, optimizer, filename=\"best_model.pth\", device='cuda'):\n",
    "    \"\"\"Load the model checkpoint.\"\"\"\n",
    "    checkpoint = torch.load(filename, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    print(f\"Model loaded from {filename} (Resuming from epoch {start_epoch})\")\n",
    "    return model, optimizer, start_epoch\n",
    "\n",
    "\n",
    "\n",
    "def augment_data(train_data, train_labels):\n",
    "    \"\"\" Augments data by oversampling and adding noise. \"\"\"\n",
    "    train_dribble_data = train_data[train_labels == 0]\n",
    "    train_pass_data = train_data[train_labels == 1]\n",
    "    train_shot_data = train_data[train_labels == 2]\n",
    "    train_rebound_data = train_data[train_labels == 3]\n",
    "\n",
    "    # Define target size as the largest class (dribble in this case)\n",
    "    target_size = len(train_dribble_data)\n",
    "    num_pass = len(train_pass_data)\n",
    "    num_shot = len(train_shot_data)\n",
    "    num_rebound = len(train_rebound_data)\n",
    "    pass_augment_size = target_size - num_pass\n",
    "    shot_augment_size = target_size - num_shot\n",
    "    rebound_augment_size = target_size - num_rebound\n",
    "\n",
    "    #lets downsample passes. NOTE: after mirroring data across y axis we had more passes than dribbles so need to downsample\n",
    "    train_pass_data = train_pass_data[torch.randperm(len(train_pass_data))[:target_size]]\n",
    "\n",
    "    # Oversample shots and rebounds\n",
    "    shot_indices = torch.randint(0, num_shot, (shot_augment_size,))\n",
    "    rebound_indices = torch.randint(0, num_rebound, (rebound_augment_size,))\n",
    "\n",
    "    shot_oversampled = train_shot_data[shot_indices]\n",
    "    rebound_oversampled = train_rebound_data[rebound_indices]\n",
    "\n",
    "    # Apply random jitter to augmented data\n",
    "    shot_jittered_augmented = add_noise(shot_oversampled, noise_std=0.02)\n",
    "    rebound_jittered_augmented = add_noise(rebound_oversampled, noise_std=0.02)\n",
    "\n",
    "    # Combine oversampled and jittered data\n",
    "    balanced_train_pass_data = train_pass_data\n",
    "    balanced_train_shot_data = torch.cat([train_shot_data, shot_jittered_augmented], dim=0)\n",
    "    balanced_train_rebound_data = torch.cat([train_rebound_data, rebound_jittered_augmented], dim=0)\n",
    "\n",
    "    print(\"Dribble data size:\", len(train_dribble_data))\n",
    "    print(\"Pass data size:\", len(balanced_train_pass_data))\n",
    "    print(\"Shot data size:\", len(balanced_train_shot_data))\n",
    "    print(\"Rebound data size:\", len(balanced_train_rebound_data))\n",
    "    # Combine all classes back together\n",
    "    augmented_train_data = torch.cat([train_dribble_data, balanced_train_pass_data, balanced_train_shot_data, balanced_train_rebound_data], dim=0)\n",
    "    augmented_train_labels = torch.cat([\n",
    "        torch.zeros(len(train_dribble_data), dtype=torch.long),  # Dribble labels (0)\n",
    "        torch.ones(len(balanced_train_pass_data), dtype=torch.long),  # Pass labels (1)\n",
    "        torch.full((len(balanced_train_shot_data),), 2, dtype=torch.long),  # Shot labels (2)\n",
    "        torch.full((len(balanced_train_rebound_data),), 3, dtype=torch.long)  # Rebound labels (3)\n",
    "    ])\n",
    "\n",
    "    return augmented_train_data, augmented_train_labels\n",
    "\n",
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    # Training model with fixed numbre of epochs\n",
    "   \n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for i, (data, labels) in enumerate(train_loader):\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def evaluate(model, val_loader, criterion, device):\n",
    "    num_classes = 4\n",
    "    # Evaluate model on validation set\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "    # Per-class accuracy tracking\n",
    "    class_correct = [0] * num_classes\n",
    "    class_total = [0] * num_classes\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, labels in val_loader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            correct_preds += (predicted == labels).sum().item()\n",
    "            total_preds += len(labels)\n",
    "\n",
    "            # Track per-class accuracy\n",
    "            for label, pred in zip(labels, predicted):\n",
    "                class_correct[label] += (label == pred).item()\n",
    "                class_total[label] += 1\n",
    "    # Overall Accuracy\n",
    "    val_loss = total_loss / len(val_loader)\n",
    "    val_accuracy = correct_preds / total_preds * 100\n",
    "\n",
    "    # Per-class accuracy\n",
    "    class_accuracies = [\n",
    "        100 * class_correct[i] / class_total[i] if class_total[i] > 0 else 0.0\n",
    "        for i in range(num_classes)\n",
    "    ]\n",
    "    return val_loss, val_accuracy, class_accuracies\n",
    "\n",
    "def k_fold_strat_cross_validation(model_class, dataset, input_dim, k=5,epochs=15, batch_size=64,\n",
    "                            d_model=256, nhead=8, num_layers=6, dropout=0.1, \n",
    "                            learning_rate=5e-5, num_classes=4, checkpoint_path='best_model.pth'):\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    class_names = ['Dribble', 'Pass', 'Shot', 'Rebound']\n",
    "    # Labels array for stratification (one label per dataset item)\n",
    "    labels = np.array([dataset[i][1] for i in range(len(dataset))])\n",
    "\n",
    "    # stratified Kfold\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    best_accuracy = 0.0 # Track the best accuracy\n",
    "    best_model_state = None # Track the best model state dict\n",
    "\n",
    "    fold_accuracies = []  \n",
    "    fold_class_accuracies = {i: [] for i in range(num_classes)}       \n",
    "    fold_losses = []             \n",
    "    all_training_losses = []     \n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(np.zeros(len(labels)), labels)):\n",
    "        print(f\"Fold {fold + 1}/{k}\")\n",
    "\n",
    "        # pre-augmentation sample sizes and class mix\n",
    "        y_tr = labels[train_idx]\n",
    "        y_va = labels[val_idx]\n",
    "        tr_counts = np.bincount(y_tr, minlength=num_classes) # get training class counts\n",
    "        va_counts = np.bincount(y_va, minlength=num_classes) # get validation class counts\n",
    "\n",
    "        print(f\"[Pre-aug] train_n={len(train_idx)}  val_n={len(val_idx)}\")\n",
    "        print(\"train per-class:\", {cls: int(tr_counts[i]) for i, cls in enumerate(class_names)})\n",
    "        print(\"val   per-class:\", {cls: int(va_counts[i]) for i, cls in enumerate(class_names)})\n",
    "\n",
    "        train_data, train_labels = zip(*[dataset[i] for i in train_idx])\n",
    "        train_data = torch.stack(train_data)\n",
    "        train_labels = torch.tensor(train_labels)\n",
    "\n",
    "        # We still need to augment as there are more dribbles than other classes\n",
    "        augmented_train_data, augmented_train_labels = augment_data(train_data, train_labels)\n",
    "\n",
    "        train_loader = DataLoader(TensorDataset(augmented_train_data, augmented_train_labels), batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(Subset(dataset, val_idx), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Initialize the model, criterion, and optimizer\n",
    "        model = model_class(input_dim, sequence_length, num_joints, num_features, \n",
    "                            d_model, nhead, num_layers, num_classes, dropout).to(device)\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        # Training loop\n",
    "        training_losses = []\n",
    "        for epoch in range(epochs):\n",
    "            train_loss = train(model, train_loader, criterion, optimizer, device)\n",
    "            training_losses.append(train_loss)\n",
    "            print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.4f}\")\n",
    "\n",
    "        # Evaluate on validation set\n",
    "        val_loss, val_accuracy, class_accuracies = evaluate(model, val_loader, criterion, device)\n",
    "        print(f\"Fold {fold + 1} Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\\n\")\n",
    "\n",
    "        fold_accuracies.append(val_accuracy)\n",
    "        fold_losses.append(val_loss)\n",
    "        all_training_losses.append(training_losses)\n",
    "\n",
    "        for class_idx in range(num_classes):\n",
    "            fold_class_accuracies[class_idx].append(class_accuracies[class_idx])\n",
    "\n",
    "        # Save the best model based on highest validation accuracy\n",
    "        if val_accuracy > best_accuracy:\n",
    "            best_accuracy = val_accuracy\n",
    "            best_model_state = model.state_dict()\n",
    "            save_checkpoint(model, optimizer, epoch, filename=checkpoint_path)\n",
    "\n",
    "\n",
    "    # Performance Metrics\n",
    "    mean_accuracy = np.mean(fold_accuracies)\n",
    "    std_accuracy = np.std(fold_accuracies)\n",
    "    min_accuracy = np.min(fold_accuracies)\n",
    "    max_accuracy = np.max(fold_accuracies)\n",
    "\n",
    "    print(f\"Mean Accuracy: {mean_accuracy:.2f}%\")\n",
    "    print(f\"Accuracy Variance: {std_accuracy:.2f}\")\n",
    "    print(f\"Worst Fold Accuracy: {min_accuracy:.2f}%\")\n",
    "    print(f\"Best Fold Accuracy: {max_accuracy:.2f}%\")\n",
    "\n",
    "    # Generate 95% confidence interval\n",
    "    confidence_interval = 1.96 * std_accuracy / np.sqrt(k)\n",
    "    ci_lower = mean_accuracy - confidence_interval\n",
    "    ci_upper = mean_accuracy + confidence_interval\n",
    "    print(f\"Confidence Interval: {confidence_interval}\")\n",
    "    print(f\"95% Confidence Range: ({ci_lower:.2f} - {ci_upper:.2f})\")\n",
    "\n",
    "    \n",
    "    # Per-Class Accuracy Metrics\n",
    "    \n",
    "    for class_idx in range(num_classes):\n",
    "        class_mean = np.mean(fold_class_accuracies[class_idx])\n",
    "        class_std = np.std(fold_class_accuracies[class_idx])\n",
    "        class_ci_range = 1.96 * (class_std / np.sqrt(k))\n",
    "\n",
    "        print(f\"Class {class_names[class_idx]} Accuracy: {class_mean:.2f}% ± {class_ci_range:.2f}%\"\n",
    "              f\" (Range: {class_mean - class_ci_range:.2f}% to {class_mean + class_ci_range:.2f}%)\")\n",
    "\n",
    "\n",
    "  \n",
    "    # Visualize Graphs\n",
    "    # Accuracy per Fold\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(range(1, k + 1), fold_accuracies, marker='o', linestyle='-', label='Fold Accuracy')\n",
    "    plt.title(\"Fold-Wise Accuracy\")\n",
    "    plt.xlabel(\"Fold\")\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.xticks(range(1, k + 1))\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Per-Class Accuracy Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for class_idx in range(num_classes):\n",
    "        class_acc = fold_class_accuracies[class_idx]\n",
    "        class_ci = 1.96 * (np.std(class_acc) / np.sqrt(k))\n",
    "\n",
    "        plt.errorbar(\n",
    "            x=range(1, k + 1),\n",
    "            y=class_acc,\n",
    "            yerr=class_ci,\n",
    "            fmt='o-', capsize=5, label=f'Class {class_names[class_idx]} ± CI'\n",
    "        )\n",
    "\n",
    "    plt.title(\"Per-Class Accuracy with Confidence Intervals J4\")\n",
    "    plt.xlabel(\"Fold\")\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.grid(False)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Training Loss per Epoch for Each Fold\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i, losses in enumerate(all_training_losses):\n",
    "        plt.plot(range(1, epochs + 1), losses, label=f'Fold {i + 1}')\n",
    "    plt.title(\"Training Loss per Epoch\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(False)\n",
    "    plt.show()\n",
    "\n",
    "    # Accuracy Distribution (Box Plot)\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.boxplot(fold_accuracies)\n",
    "    plt.title(\"Accuracy Distribution Across Folds J4\")\n",
    "    plt.xlabel(\"K-Fold Results\")\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.show()\n",
    "\n",
    "    # Visualizing Confidence Intervals\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.errorbar(\n",
    "        x=range(1, k + 1),\n",
    "        y=fold_accuracies,\n",
    "        yerr=confidence_interval,\n",
    "        fmt='o', capsize=5, label='Fold Accuracy ± CI'\n",
    "    )\n",
    "    plt.title(\"K-Fold Accuracy with Confidence Intervals J4\")\n",
    "    plt.xlabel(\"Fold\")\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.grid(False)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Lets return the best model state\n",
    "    model.load_state_dict(best_model_state) # it may not be the last fold which is why we have to load\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, Evaluate, and save Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Wrap train/val data in TensorDataset for K-Fold\n",
    "train_val_dataset = TensorDataset(combined_data, labels)\n",
    "\n",
    "# Define model checkpoint path. This is location where we save the model\n",
    "checkpoint_path = ' '\n",
    "\n",
    "# Define model parameters. Input the best model parameters from the hyperparmeter tuning\n",
    "input_dim = num_joints * num_features + 3\n",
    "sequence_length = 21\n",
    "num_classes = 4\n",
    "d_model = 128\n",
    "nhead = 8\n",
    "num_layers = 6\n",
    "dropout = 0.1\n",
    "lr = 0.00010236630901374436\n",
    "num_epochs = 15\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "# Run KFold cross validation\n",
    "k_test = 5\n",
    "\n",
    "\n",
    "best_model = k_fold_strat_cross_validation(PoseTransformer, train_val_dataset, input_dim=input_dim, k=k_test, epochs=num_epochs, batch_size=batch_size,\n",
    "                        d_model=d_model, nhead=nhead, num_layers=num_layers, dropout=dropout, \n",
    "                        learning_rate=lr, num_classes=num_classes, checkpoint_path=checkpoint_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
